1. You can either hangout around happiness vampires or change the world, but you cannot do both.

---------------------------------------------------
Additional Resources:
Pattern Recog and Machine L: Bishop

Practical Examples in R

ML for hackers

Dr. Andrew Ng from Standford

The elements of stat Hastie, Tibshirani and Friedman

Information Theory, Inference, and Learning Algorithms David Mackay

-----------------------------------------------------------------


DS is essentially an experiment that you keep building on until an outcome stage is achieved.

Formula:

P = Performance, E = Experience, M = Model (formula)


expressed as an optimization problem:
	P * (M/E) -> Max  

learn matrices, linear algebra

Types of supervised learning:

	Regression - Continuous output

	Classification - Animal cat or dog? Spam email or phish?

	Applications: Web email spam, Web authentic? Medicine cell cancerous or not? OCR Recognizing characters and symbols

	Decision Trees! very interesting
	In general, decision trees are constructed via an algorithmic approach that identifies ways to split a data set based on different conditions. It is one of the most widely used and practical methods for supervised learning. Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.

	My opinion: decision trees can only be used with predictable outcomes, not unpredictable. 

    Instances: Refer to the vector of features or attributes that define the input space
    Attribute: A quantity describing an instance
    Concept: The function that maps input to output
    Target Concept: The function that we are trying to find, i.e., the actual answer
    Hypothesis Class: Set of all the possible functions
    Sample: A set of inputs paired with a label, which is the correct output (also known as the Training Set)
    Candidate Concept: A concept which we think is the target concept
    Testing Set: Similar to the training set and is used to test the candidate concept and determine its performance

    A general algorithm for a decision tree can be described as follows:

    Pick the best attribute/feature. The best attribute is one which best splits or separates the data.
    Ask the relevant question.
    Follow the answer path.
    Go to step 1 until you arrive to the answer.



Unsupervised Learning:
	Mainly deals with unlabelled data.
	Unsupervised machine learning finds all kind of unknown patterns in data, help you to find features which can be useful for categorization.
	Markov, clustering, pattern detection, CNN

Hierarchical Clustering (example of Agglomerative Clustering) - an algorithm which builds a hierarchy of clusters. It begins with all the data which is assigned to a cluster of their own. Here, two close cluster are going to be in the same cluster. This algorithm ends when there is only one cluster left. 


Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.

Different estimators are better suited for different types of data and different problems.


Learn to use matplotlib, seaborn, ggplot, kibana, read docs, examples

learn to use lambda func.

learn PCA: Pricipal Component Analysis
learn Dimensionality Reduction
SVM, SVR, Random forest, non negative matrix factorization,

mean-shift, spectral clustering,

Model Selection: you get help from scikit learn to pick the right model. grid search, cross validationm, metrics

Preprocessing: feature extraction and normalization

feature engineering



pd.factorize() assigns a number to categories
or use pd.merge
or use one hot encoder from scikit learn preprocessing

scikitlearn z scoring, standardScaler

Normalization, Decorrelation, data whitening, 

scikitlearn.metrics , classification report

--------------------------------
DEEP LEARNING

In most cases, a deep learning framework
provides frozen spots and hot spots in these areas: 
    Hardware access (such as using a GPU with ease) 
    Standard neural network layer access 
    Deep learning primitive access 
    Computational graph management 
    Model training 
    Model deployment 
    Model testing 
    Graph building and presentation 
    Inference (forward propagation) 
    Automatic differentiation (backpropagation) 

--------------------------------------------------------------------------
STATISTICS
Things to know: poisson distribution, multiple linear regression, Pearson corelation coefficient, Spearmans Rank Coefficient, The central limit theorem, normal distribution, binomial distribution, Conditional Probability

--------------------------------------------------------------------------
